### Pandas解析函数

```python
read_csv	#从文件或url或文件类型对象读取数据，默认,分割
read_table	#默认\t
read_fwf
read_clipboard
read_excel
read_hdf
read_html
read_json
read_msgpack
read_packle
read_sas
read_sql
read_stata
read_feather

```

这些函数的可选参数主要有以下几种类型

- 索引，可以将一或多列作为返回的DataFrame，从文件或用户处获得列名或没有列名
- 类型推断和数据转换
- 日期时间解析
- 迭代
- 未清洗数据问题

原数据文件

```
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
```

```python
df = pd.read_csv('examples/ex1.csv')
df
Out[6]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

```

我们也可也通过read_table并指定分隔符

```python
pd.read_table('examples/ex1.csv',sep=',')
Out[5]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

```

有些表没有表头如

```python
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
```

如果我们需要读取该文件，你需要选择一些选项。你可以允许pandas自动分配列名，也可以自己指定列明

```python
pd.read_csv('examples/ex2.csv',header=None)
   0   1   2   3      4
0  1   2   3   4  hello
1  5   6   7   8  world
2  9  10  11  12    foo

pd.read_csv('examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])
Out[8]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

```

如果想要message列称为返回DataFrame的索引，你可以指定位置4的列为索引，或将message传给参数`index_col`

```python
names = ['a', 'b', 'c', 'd', 'message']
pd.read_csv('examples/ex2.csv', names=names, index_col='message')
Out[9]: 
         a   b   c   d
message               
hello    1   2   3   4
world    5   6   7   8
foo      9  10  11  12
```

当想要从多个列中形成一个分层索引，需要传入一个包含列序号或列明的列表

```python
key1,key2,value1,value2
one,a,1,2
one,b,3,4
one,c,5,6
one,d,7,8
two,a,9,10
two,b,11,12
two,c,13,14
two,d,15,16




parsed = pd.read_csv('examples/csv_mindex.csv', index_col=['key1', 'key2'])
parsed
Out[11]: 
           value1  value2
key1 key2                
one  a          1       2
     b          3       4
     c          5       6
     d          7       8
two  a          9      10
     b         11      12
     c         13      14
     d         15      16
```

在某些情况下，一张表的分隔符不是固定的，使用空白或者其他方式来进行分割

```python
            A         B         C
aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
ccc -0.264273 -0.386314 -0.217601
ddd -0.871858 -0.348382  1.100491

```

此时可以使用正则表达式所谓分隔符，在本例中正则表达式为`\s+`因此可以得到

```python
result = pd.read_table('examples/ex3.txt', sep='\s+')
result
Out[12]: 
            A         B         C
aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
ccc -0.264273 -0.386314 -0.217601
ddd -0.871858 -0.348382  1.100491
```

在本例中因为列名的数量比数据的列数少一，因此read_csv推断第一列应当为索引。

解析函数有很多附加参数帮助我们处理各种发送异常的文件格式

我们可以使用skiprows来跳过第一行，第三行和第四行

```python
# hey!
a,b,c,d,message
# just wanted to make things more difficult for you
# who reads CSV files with computers, anyway?
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo


pd.read_csv('examples/ex4.csv', skiprows=[0, 2, 3])
Out[13]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo



```

缺失值处理，在文件解析的过程中很重要！！！，通常情况下，缺失值要么不显示，要么用一些标识值。默认情况下，pandas使用常见的标识值如NA和NULL

```python
something,a,b,c,d,message
one,1,2,3,4,NA
two,5,6,,8,world
three,9,10,11,12,foo


result = pd.read_csv('examples/ex5.csv')
result
Out[11]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo

pd.isnull(result)
Out[12]: 
   something      a      b      c      d  message
0      False  False  False  False  False     True
1      False  False  False   True  False    False
2      False  False  False  False  False    False

```

`nv_values`选项可以传入一个列表或一组字符串来处理缺失值

```python
result = pd.read_csv('examples/ex5.csv', na_values=['NULL'])
result
Out[13]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo
```

在使用字典的时候，每列可以指定不同的缺失值

```python
sentinels = {'message': ['foo', 'NA'], 'something': ['two']}
pd.read_csv('examples/ex5.csv',na_values=sentinels)
Out[14]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       NaN  5   6   NaN   8   world
2     three  9  10  11.0  12     NaN
```

### 常用函数参数

```python
path	#文件系统位置的字符串，url或文件型对象
sep/delimiter 	#用于分割每行字段的字符序列或正则表达式
header	#用作列名的行号，默认为0，如果没有列名的话则为None
index_col	#用作结果中的列号或列名，可以是一个单一的名称或数字，也可以是一个分层索引
names	#结果的列名列表，和header=None一起用
skiprows	#需要跳过的行号或者列表
na_values
comment	#在行结尾处分隔注释的符号
parse_dates	#尝试将数据解析为datetime，默认是False，如果是True，将尝试解析所有的列，也可以指定列号或者行号来进行解析，如果列表元素是元组或列表，将会把多个列组合在一起进行解析
keep_date_col	#如果连接到解析日期上，保留被链接的列，默认为False
converters	#包含列名称映射到函数字典，比如`{'foo':f}`会将函数f映射到foo列
dayfirst	#解析非明确日期时，按照国际格式处理，默认为False
date_parser	#用于解析日期的函数
nrows	#从文件头处读入的行数
iterator	#返回一个TextParser对象，用于零散的读入文件
chunksize	#用于迭代的块大小
skip_footer	#返回文件尾部的行数
verbose	#打印各种解析器输出的信息
encoding
squeeze	#如果解析函数只包含一列，返回Series
thousands	#千位分隔符例如`,  .`

```

## 1. 分块写入文本文件

当处理大小文件或找出正确的参数集来正确处理大文件时，我们可能需要读入文件的一个小片段或按小块便利文件

当场是大文件的时候，我们可以先对pandas的显示设置进行调整，使之更加紧凑

```python
pd.options.display.max_rows = 10
result = pd.read_csv('examples/ex6.csv')
result
Out[7]: 
           one       two     three      four key
0     0.467976 -0.038649 -0.295344 -1.824726   L
1    -0.358893  1.404453  0.704965 -0.200638   B
2    -0.501840  0.659254 -0.421691 -0.057688   G
3     0.204886  1.074134  1.388361 -0.982404   R
4     0.354628 -0.133116  0.283763 -0.837063   Q
        ...       ...       ...       ...  ..
9995  2.311896 -0.417070 -1.409599 -0.515821   L
9996 -0.479893 -0.650419  0.745152 -0.646038   E
9997  0.523331  0.787112  0.486066  1.093156   K
9998 -0.362559  0.598894 -1.843201  0.887292   G
9999 -0.096376 -1.012999 -0.657431 -0.573315   0
[10000 rows x 5 columns]

```

如果你只想读一小部分行，可以指明`nrows`

```python
pd.read_csv('examples/ex6.csv',nrows=5)
Out[8]: 
        one       two     three      four key
0  0.467976 -0.038649 -0.295344 -1.824726   L
1 -0.358893  1.404453  0.704965 -0.200638   B
2 -0.501840  0.659254 -0.421691 -0.057688   G
3  0.204886  1.074134  1.388361 -0.982404   R
4  0.354628 -0.133116  0.283763 -0.837063   Q
```

为了分块读入文件，可以指定chunksize作为每一块的行数

```python
chunker = pd.read_csv('examples/ex6.csv',chunksize=1000)
chunker
Out[10]: <pandas.io.parsers.readers.TextFileReader at 0x209e2e22e50>


```

返回的TextFileReader允许根据chunksize进行遍历文件，例如我们可以遍历ex6.csv，并对key列聚合获得计数值

```python
chunker = pd.read_csv('examples/ex6.csv', chunksize=1000)
tot = pd.Series([], dtype=np.float64)
for piece in chunker:
    tot = tot.add(piece['key'].value_counts(), fill_value=0)
tot.iloc[:20]

0    151.0
1    146.0
2    152.0
3    162.0
4    171.0
     ...  
F    335.0
G    308.0
H    330.0
I    327.0
J    337.0
Length: 20, dtype: float64
```

## 2. 将数据写入文本格式

数据可以导出为分割的形式，让我们看下之前读取的csv文件

```python
data = pd.read_csv("examples/ex5.csv")
data
Out[9]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo
```

使用dataframe的to_csv方法，我们可以将数据导出为，分隔符的文件

```python
data.to_csv('out.csv')

,something,a,b,c,d,message
0,one,1,2,3.0,4,
1,two,5,6,,8,world
2,three,9,10,11.0,12,foo
```

当然可以使用sys.stdout来显示结果

```python
import sys
data.to_csv(sys.stdout, sep='|')

|something|a|b|c|d|message
0|one|1|2|3.0|4|
1|two|5|6||8|world
2|three|9|10|11.0|12|foo
```

缺失值在输出时以空字符串出现，也许想要其他标识值对缺失值进行标注

```python
data.to_csv(sys.stdout,na_rep='NULL')
,something,a,b,c,d,message
0,one,1,2,3.0,4,NULL
1,two,5,6,NULL,8,world
2,three,9,10,11.0,12,foo


```

如果没有其他指定的话，行和列的标签都会被写入，不过两者都可以禁止使用

```python
data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c'])

data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c'])
a,b,c
1,2,3.0
5,6,
9,10,11.0
```

同样Series也有to_csv方法

```python
dates = pd.date_range('1/1/2000',periods=7)
dates
Out[15]: 
DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04',
               '2000-01-05', '2000-01-06', '2000-01-07'],
              dtype='datetime64[ns]', freq='D')

ts = pd.Series(np.arange(7),index=dates)
ts
Out[17]: 
2000-01-01    0
2000-01-02    1
2000-01-03    2
2000-01-04    3
2000-01-05    4
2000-01-06    5
2000-01-07    6
Freq: D, dtype: int32

ts.to_csv('out.csv')
,0
2000-01-01,0
2000-01-02,1
2000-01-03,2
2000-01-04,3
2000-01-05,4
2000-01-06,5
2000-01-07,6

```

## 3. 使用分隔格式

绝大多数表数据类型都可以使用函数`pandas.read_table`函数进行读取，但是有些时候可以使用手动操作。接收一个带有一行或多行错误的文件并不少见，`read_table`也无法解决这种情况

```python
"a","b","c"
"1","2","3"
"1","2","3"
```

多余任何带有单字符的文件，都可以使用python内建的csv模块。要使用它需要将任一打开的文件或文件对象穿个`csv.reader`

```python
f = open('examples/ex7.csv')
reader = csv.reader(f)

```

像遍历文件那样遍历reader会产生元组，元组的值为删除了引号的字符

```python
for line in reader:
    print(line)
    
['a', 'b', 'c']
['1', '2', '3']
['1', '2', '3']
```

之后你就可以自行做一些必须处理，

```python
with open('examples/ex7.csv') as f:
    lines = list(csv.reader(f))
header , values = lines[0],lines[1:]
data_dic = {h: v for h, v in zip(header, zip(*values))}
data_dic
Out[5]: {'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}
```

csv文件有多种不通过风格。如果需要根据不同的分隔符，字符串引用约定或行终止符定义一个新的格式时，我们可以使用`csv.Dialect`定义一个简单的子类

```python
# %%

class my_dialect(csv.Dialect):
    lineterminator = '\n'
    delimiter = ';'
    quotechar = '"'
    quoting = csv.QUOTE_MINIMAL


reader = csv.reader(f, dialect=my_dialect)
```

我们也可以直接将csv方言参数传入cvs.reader的关键字参数

```python
reader = csv.reader(f, dialect='|')
```

### csv方言选项

```python
delimiter #用于分割字段的字符，默认','
lineterminator	#行终止符，默认`\r\n`会自动识别跨平台的终止符
quotechar	#用在含有特殊字符字段的引号,默认为`"`
quoting		#引用惯例。选项包含csv.QUOTE_ALL引用所有字段，csv.QUOTE_MINIMAL只使用特殊字符   csv.QUOTE_NONUMERIC和csv.QUOTE_NONE不引用，细节参考文档，默认QUOTE_MINIMAL
skipinitialspace	#忽略每个分隔符后的空白，默认为False
doublequote		#如何处理字段内部的引号，如果为True，则是双引号，具体查看文档
escapechar		#引用设置为csv.QUOTE_NONE时用于转义分隔符的字符串，默认禁用
```

> 如果遇到更加复杂的情况我们不得不使用字符串的split方法或者正则表达式方法re.split进行拆分和其他清理工作

需要手动写入被分隔文件时，你可以使用csv.writer,接收可写入文件对象，以及和reader一样的csv语言

```python
with open('mydate.csv', 'w') as f:
    writer = csv.writer(f, dialect=my_dialect)
    writer.writerow(('one', 'two', 'three'))
    writer.writerow(('1', '2', '3'))
    writer.writerow(('4', '5', '6'))
    writer.writerow(('7', '8', '9'))

    
one;two;three
1;2;3
4;5;6
7;8;9

```

