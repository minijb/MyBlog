## 1. 图的基本结构

- V：Vertex(or node) attributes

![image.png](https://s2.loli.net/2022/09/23/KMNLE2lat8qyYxn.png)

- E:  Edge(or link) attributes and directions

![image.png](https://s2.loli.net/2022/09/23/R3XIN49aOr67mEY.png)

- U:  Global (or master node) attributes

![image.png](https://s2.loli.net/2022/09/23/BimylNaVd94vAzk.png)

### how to describe these element

- Vertex (or node) embedding
- Edge (or link) attributes and embedding
- Global (or master node) embedding

简单来说，就是将每个元素向量化来进行表示

![image.png](https://s2.loli.net/2022/09/23/IZtrA2lRbG8woMW.png)

### two types of graphs

- undirected edge
- directed edge

![image.png](https://s2.loli.net/2022/09/23/Xjcvkf49tns675l.png)

## 2. 如何将数据表示为图

### 2.1 Image as graphs

我们通常情况下认为图作为一种长方形网格(算上通道也就是三层网格)，我将用(`i*j*3`)的数组形式来表示他们。

另一种表现图片的方式是：每一个像素点代表一个node，并且通过一条边与相邻的像素连接。也就是说每一个非边界像素点都有8个临界点。存储在node中的信息是一个3为的向量，用来代表每个像素点的RGB信息。

我们通过一个邻接矩阵的方式来表示边的连接(第二幅图)

![image.png](https://s2.loli.net/2022/09/25/C67WbJBKTMaUktR.png)

### 2.2 Text as graghs

我们可以将索引关联到每一个字符/词语来序列化文本，并且将文本表示为遗传这些索引。这就建立了一个简单的有向图，在这幅图中每一个单词或者词语是一个节点并通过一条边连接在一起。

![image.png](https://s2.loli.net/2022/09/25/54jGlsecuaFyZvN.png)

******

在通常情况下这些表示方法是冗余的(这些图都是有规律吧的)，可以看的出来图的邻接矩阵是一个带状对角矩阵，而文本的则是一个对角线。

### 2.3 在自然界中图类型数据

- 分子结构
- 人际关系
- 社交图
- 引用图(有向边)

![image.png](https://s2.loli.net/2022/09/25/m8QUaJVxyCbLf3N.png)

## 3. 图可以定义什么问题

three general types of prediction tasks on graphs

-  graph-level
- node-level
- edge-level

### 3.1 Graph-level task

goal : predict the property of an entire graph.

for a molecule repesented as a graph, we can  predict what the molecule smells like or whether it will bind to a receptor implicated in a disease.

![image.png](https://s2.loli.net/2022/09/25/W7VcXxTvR2wQHs3.png)

> 简单来说就是对图也就是图表示的物体进行分类或者其他的预测
>
> 举个简单的例子：对于图片可以进行分类，对于文本可以进行情感分析

### 3.2 Node-level task

- predicting the identity or role of each node within a graph

比如上文中的摔跤俱乐部中的连个导师，如果让学生进行战队，那么学生也就是顶点会选择谁。

In this case, distance between a node to either the Instructor or Administrator is highly correlated to this label.

![image.png](https://s2.loli.net/2022/09/25/IAiTbPaRzvup1UQ.png)

以此类推，Node-level task可以用于图像分割。在图像风格中我们尝试标记每一个像素点。在文本中，可以是预测一个句子中的不同词类

### 3.3 Edge-level task

![image.png](https://s2.loli.net/2022/09/25/3C8WhxjiPZ6Yq9D.png)

简单来说就是预测node之间的关系。

如图，在预测了图中的物体之后，我们可以预测物体之间的关系。我们可以将这种表示为边级别的分类。

- 给了node以及它在图片中代表的意义
- 我们希望预测这些node共享了那条边，以及这些边的意义
- 我们可以认为图是完全连接的，之后进行裁剪得到一个稀疏的图

![image.png](https://s2.loli.net/2022/09/25/RNv97sja6CTQexH.png)

## 4. 挑战

- 如何表示一张图来适配神经网络

图有四种信息可以用来进行预测：nodes,edges,global-context,connectivity

前三种很直观，但是第四种也就是连通性就很复杂。

很显然我们可以使用邻接表，但是这种方式一些缺点。

- the number of nodes in a graph can be on the order of millions, and the number of edges per node can be highly variable

- 这很有可能导致，空间效率低下

另一个问题就是节点的不同的排列产生的效果不一样(如下图所示)

![image.png](https://s2.loli.net/2022/09/26/QiZvC4Yz3aDqbKX.png)

### 3.1 解决方案

一种优雅而高效的方案来表示系数矩阵的图的方法是

- 邻接列表

我们使用一个元组`(i,j)`来描述$e_k$($n_i$和$n_j$之间的边)，同时我们不去存储没有连接的边

![image.png](https://s2.loli.net/2022/09/26/3oaqphtwdYlJ5k4.png)

> 在此处使用标量来定义顶点和边，当然我们通常使用向量来表示，这对结果没有影响
>
> 如果使用向量的话，就不是一个列表而是一个矩阵比如$[n_{nodes},node_{dim}]$

## 5. 图神经网络

**A GNN is an optimizable transformation on all attributes of the graph (nodes, edges, global-context) that preserves graph symmetries (permutation invariances)**

使用的是message passing neural network,GNN采用*图入，图出*模式，也就是说我们输入一张图，在不改变其连通性的前提下，逐步改变其内部信息，最后输出一张图

### 5.1 最简单的图神经网络

注：这里我们没有使用到连通性

这里我们使用了一个单独的多层感知机(当然也可以使用其他的网络结构在这个图的其他部分)，我们将这一层称为GNN layer。对于节点向量，我们通过MLP得到一个经过优化的节点向量，我已以此类推运用到边以及总体信息上，最后得到一个新的图

![image.png](https://s2.loli.net/2022/09/26/vs3g6SVQZHCqUix.png)

我们可以以上步骤来使用多个GNN layers。

经过以上步骤，我们得到了一个和输入结构相同的图(内部信息改变，但是结构不变)

### 5.2 通过池化信息得到GNN的预测结果

我们可以认为本例是一个二分类问题，当然这个结构也可以很简单的扩展为多分类问题或者回归问题。

如果我们的任务是在节点上进行二分类，并且图已经包含了节点的信息，那么我们的方法就是**对每一个节点进行线性回归**

![image.png](https://s2.loli.net/2022/09/26/I4TB8kKGFRQbtV2.png)

> 注：所有节点使用同一个回归模型！！







> - 视频
>
> https://www.bilibili.com/video/BV1iT4y1d7zP/?spm_id_from=333.337.search-card.all.click&vd_source=8beb74be6b19124f110600d2ce0f3957
>
> - 对应的blog
>
> https://distill.pub/2021/gnn-intro/