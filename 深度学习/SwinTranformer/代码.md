swin --- shifted window --- 移动窗口

Hierarchical --- 层级式的

也就是说，让transformer可以和卷积一样进行移动的层级的训练

可以作为CV的一种普遍的框架

**挑战**

- 尺度的问题，同一种标签的在同一张图片上的大小是不一样的，在NLP方面这个是没有问题的
- resolution太大了，

**swin-transformer**

- 本文中，特征是通过滑动窗口的方式提取的
  - 效率更高
  - 移动窗口带来cross-window connection也就是说移动窗口提取的特征在相邻的窗口上有了交互
  - 模型大小的是线性的而不是平方的
- 分层式接口提供多尺度的特征

## 引言

先讲了一下VIT

![image.png](https://s2.loli.net/2022/11/16/WqVogMLik24CDeT.png)

VIT将图片分割为16，16，也就是16倍的下采样，自始至终都是16被下采样。因此多尺度信息是没有的。

同时，VIT始终实在整图中进行的，也就是全局建模，参数量是指数级的

Swin Trans

- 是在小的图片块中计算注意力

- 增加感受野的方法：patch merging

**移动窗口**

元素单元: patch,local-windows

![image.png](https://s2.loli.net/2022/11/16/Sufnx9LeGmVszcQ.png)

简单来说就是将layer1中的窗口向左下移动

<img src="https://s2.loli.net/2022/11/16/zDt3sEhUbcyKHkp.png" alt="image.png" style="zoom: 50%;" />

在原本中，一个window中的patch是无法和其他window中的patch互动的，在移动windows后，patch是可以和新的patch互动的

## 实验方法

### 1. 总体结构

- 原本图片的大小： `224*224*3`
- 使用patch进行划分
  - patch的size: `4*4`----feature dimension = `4*4*3`
  - 处理后图片的大小${H \over 4}+{W \over 4}*48$---(48 = `4*4*3`) ------`56 *56 *48`

> 此处划分也就是将每个patch中的像素拉长拼接每个patch中的特征长度就是48

- Linear Embedding---卷积操作
  - 此处官方设置output的特征长度为96  ---- ` 56 * 56 *96`
  - 在送入到transformer中之前  需要拉直  ----- `3136 * 96`
- 使用窗口自注意力机制的swin-transformer层
  - 输出的温度就是`56 * 56 * 96`
- 之后的transformer我们需要提取多尺度的特征
  - 在CNN中我们使用的是池化操作
  - 这里我们使用patch merging
  - 也就是说，空间上更小了，但是维度更高了
  - 同时为了保持和卷积一样的效果---维度仅仅是翻倍被捕时翻4倍，使用1*1的卷积将通过到数变为2倍
  - 此次输出为` 28 * 28 *192` 之后的block 长宽降低，通道翻倍
  - `14 * 14 * 384` ----`7 * 7 * 768`

![image.png](https://s2.loli.net/2022/11/20/uE4BdlDkCxpsAHc.png)

> 注意：swin-transformer 不是通过 添加token进行分类预测的---是在最后进行全局池化操作完成分类任务的

> 可以看出swin transformer的结构就是在尽可能的模仿CNN

### 基于移动窗口的自注意力机制

我们以第一层作为例子

第一层的输入是`56 * 56 * 96`，最小的计算单元`M*M`的patch(swin trnasformer 中 M的大小为7)，因此我们就具有`8*8 = 64`个窗口！！！

因为没有使用token--也就是没有全局建模，swin使用了移动窗口的方式来进行全局特征的提取

移动过窗口之前提到过，具体的过程就是在第一层做窗口的注意力机制，第二层做移动窗口的注意力机制，以此类推，两个部分加起来才是一个swin-transformer的基本单元！！！

![image.png](https://s2.loli.net/2022/11/20/gWSw2sI4yYLkVio.png)

### 提高移动窗口的计算性能

#### 基于masked的计算方式

如果在移动后的窗口上直接计算，也就说原本只有4个窗口现在有9个窗口，计算复杂度大幅上升！！！

swin提出一种方法，也即是cyclic shift将周围的窗口进行拼接重组为新的窗口，窗口数量还是为4

![image.png](https://s2.loli.net/2022/11/20/3Q1Xib85jL7p2DP.png)

但是根据图面的性质：上面的画面不应该和下面的画面进行自注意力机制的计算！！！，这不符合常理

**此时swin使用了掩码的方式**

在进入transformer之前我们需要把向量拉直，因为移动的位置为3，每个窗口的边上为7，因此有如下图

![image.png](https://s2.loli.net/2022/11/20/g6SwKtorT8CfeuX.png)

注意此处我们3和6之间做了自注意力机制！！！，我们是不希望不相邻的部分做自注意力的！！

<img src="https://s2.loli.net/2022/11/20/Acmkp2ZIM1wFfeX.png" alt="image.png" style="zoom: 33%;" />

我们使用如下的掩码模板，让它和结果相加，在softmax之后-100的部分就变为了0

同理，1和2的模板可以如下

<img src="https://s2.loli.net/2022/11/20/eqNrGf1zRwKhQx9.png" alt="image.png" style="zoom: 33%;" />

官方的模板如下：

![image.png](https://s2.loli.net/2022/11/20/Di9Wyrh3AfUpEI6.png)

## 不同的变体

主要改变的地方即使C的个数也就是特征的维度，以及swintransformer的个数

![image.png](https://s2.loli.net/2022/11/20/awzqVdQXLJEiC41.png)

> EffNet
>
> RegNet

> swin-transformer  的优势是在庞大数量的预训练后准确率就很高

> pytorch-image-models
>
> https://www.bilibili.com/video/BV1tP411A7hS?p=11&vd_source=8beb74be6b19124f110600d2ce0f3957

