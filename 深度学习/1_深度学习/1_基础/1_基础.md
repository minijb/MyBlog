## 1. 机器学习基础

![image.png](https://s2.loli.net/2022/10/14/wPNRUn6hg8SOjtE.png)

![image.png](https://s2.loli.net/2022/10/14/CGa5PBQ39OdkM4H.png)

![image.png](https://s2.loli.net/2022/10/14/DB3vJWoxNnzCskj.png)

![image.png](https://s2.loli.net/2022/10/14/TVF8PbvrJAURfok.png)

## 2. 深度学习基础

什么是激活函数：在$y=wx+b$的情况下，使用多个sigmod函数可以实现更加有弹性的function

![image.png](https://s2.loli.net/2022/10/16/lKVHCGRx72a4sYA.png)

那么我们如何代表这种function，我们可以使用sigmod函数进行近似

![image.png](https://s2.loli.net/2022/10/16/NneOVxljaikuKDq.png)

我们可以将这种方法延伸到更高维度

![image.png](https://s2.loli.net/2022/10/16/8jebSOWmCrA7aoi.png)

那么我们就可以看到最经典的函数模型

![image.png](https://s2.loli.net/2022/10/16/9PZC5AgFmHvqLoE.png)

以上式子我们可以使用矩阵进行表明

![image.png](https://s2.loli.net/2022/10/16/ShabQxB5IjpJKyr.png)

![image.png](https://s2.loli.net/2022/10/16/qGkd6nFyvDXsSlp.png)

### Loss

此时Loss和之前的机器学习部分也相同

![image.png](https://s2.loli.net/2022/10/16/FYnMTQ176futAOW.png)

![image.png](https://s2.loli.net/2022/10/16/eQhlMY6X9SVAfZT.png)

![image.png](https://s2.loli.net/2022/10/16/le9nmw1J7Qc6U3R.png)

### 其他激活函数

![image.png](https://s2.loli.net/2022/10/16/LDWnqwbQZxR9U1O.png)

![image.png](https://s2.loli.net/2022/10/16/Hkl8n6RFPrdmaDE.png)

