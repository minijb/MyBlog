## Abstract

### MAE approach

在输入图片中国遮盖随机patch，之后重建丢失的像素

### two core designs

- 建立一个不对称的encoder-decoder结构
  - encoder仅仅对可见部分(也就是没有被masked部分)进行encoder
  - 一个轻量化的decoder，用来从**经过encoder提取的特征**和**masked 部分**重建整个图像
- 如果在输入图片上掩盖率很高(比如75%)的话 ， 我们发现可以演变为自监督任务

### 优势

- 加速训练
- 增加准去率

## Introduction

- 思想来源于BERT和GPT---一种生成NLP模型



**回答了一个问题：语言掩码和图片自动掩码之间有什么不同**

从以下角度进行回答

- 模型之间的隔阂没了---transform进入图像处理领域
- 语言和视觉的信息密度不一样。视觉信息有很多冗余。

解决方案：使用大量掩码

减少了冗余信息，并creates a challenging self-supervisory task that requires holistic understanding beyond low-level image statistics. --- ==简单来说就是让模型学习到真正的特征而不是简单的图片统计==

- 自动编码解码器，在重建文本和图像之间扮演者着不同的角色。！！！

**视觉领域：**解码器重构像素，因此其输出具有比普通识别任务更低的语义级别。

**语言领域：**相反，重建出的单词具有很高的语义信息

==简单来说，就是重建的单词具有很高的上下文关联性---但是像素其实和周围一圈的关系不大！！！！--- 没有考虑全局信息==

<font color="red">想法 ---- 重建方面是不是可以使用不同大小的卷积块  或者考虑更多的全局信息</font>

因此，BERT对于语言来说是很平常的，但是对于图像学习潜在特征很关键。

*****

综上所述，我们提出了MAE --- 通过随机掩码 以及 非对称的编码解码器 重建掩码区域。同时其掩码率也很大---- 75%

> 可以错迁移学习

## related work

**autoencoding**

- 自己是一种去噪自动编码   ----  但是和DAE不同

> Generative Pretraining from Pixels !!!!

**masked image encoing**

> Context encoders: Feature learning by inpainting
>
> - 两部分损失---- 重建损失和生成对抗损失
>
> Neural discrete representation learning
>
> Zero-shot text-to-image generation

**自监督学习**

> Unsupervised visual representation learning by context prediction
>
> ！！！！！！！！！！！！！！！！！！！！！！！！
>
> Spatiotemporal Contrastive Video Representation Learning
>
> Unsupervised learning of visual representations by solving jigsaw puzzles
>
> 使用拼图游戏进行训练
>
> Colorful image colorization. 自监督着色
>
> Unsupervised Representation Learning by Predicting Image Rotations 使用旋转来增加自监督的精度

对比学习

Unsupervised Feature Learning via Non-Parametric Instance Discrimination

！！！！！！！！！！！！！！！

Momentum Contrast for Unsupervised Visual Representation Learning

[Exploring Simple Siamese Representation Learning](https://paperswithcode.com/paper/exploring-simple-siamese-representation)

## approach

我们采用了允许编码器仅对部分进行操作的非对称设计。

![](https://s2.loli.net/2023/02/25/YuyUGs5ecTDg8Zt.png)

可以看出---- 没有将掩码区域送入encoder。然后将这些特征和掩码组合送入decoder形成恢复图片。

**mask**

随机采样+高掩码率：**目的：**<font color='red'>让模型不能通过周围的块进行预测！！！！</font>

> 消除了中心偏执--- 未掩码区域的周围很少有现有的块进行预测

**MAE encoder**

只输入unmasked patches ，同时因为高掩码率，所以节约了内存。

**MAE decoder**

输入1. 掩码标记 2. encoder输出的特征块

这个位置是按照之前patch块的位置进行排布的。

同时decoder只在预训练中起作用，因此选择可以灵活。

**reconstruction target**

只计算掩码区域的损耗，不计算非掩码区域的损耗。----类似于BERT

> 有没有可以能需要计算非掩码区域的？？？

**另一种方案**：目标是每一个masked patch 中归一化后的像素值！！！改善了表面质量

